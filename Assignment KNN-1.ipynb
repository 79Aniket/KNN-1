{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58cbb27b-3f61-4d95-9d4d-3a0353447628",
   "metadata": {},
   "source": [
    "## Q1. What is the KNN algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b45b5ac-ae8a-4855-b55d-0684279f6c1d",
   "metadata": {},
   "source": [
    "## The K-Nearest Neighbors (KNN) algorithm is a simple, yet effective, supervised machine learning algorithm that can be used for both classification and regression tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04448466-86d0-451a-8ec1-cd7b94943bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb4958d3-1214-49a7-ba9a-108f89769292",
   "metadata": {},
   "source": [
    "## Q2. How do you choose the value of K in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0daf60-a65b-4e43-812a-12a53f85241b",
   "metadata": {},
   "source": [
    "## The optimal K value usually found is the square root of N, where N is the total number of samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc7f34-aaa2-414f-98d2-f22ce16f8c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56c87842-2686-4507-89a5-3daa4aecc091",
   "metadata": {},
   "source": [
    "## Q3. What is the difference between KNN classifier and KNN regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848887dc-5711-4d8d-a337-e7cc406f8466",
   "metadata": {},
   "source": [
    "## KNN Classifier: Categorical variable.  Classifying images as cats or dogs, classifying emails as spam or not spam, classifying patients as having a particular disease or not.\n",
    "\n",
    "## KNN Regressor:  Continuous variable.   Predicting the price of a house, predicting the number of customers who will visit a store on a given day, predicting the demand for a product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69961377-286d-47df-acf7-f21b9f47b453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a14c9b05-e250-40f0-a3d2-acf78bd16a66",
   "metadata": {},
   "source": [
    "## Q4. How do you measure the performance of KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3c2bed-f3ab-4ef9-a3b3-a362a7a8a601",
   "metadata": {},
   "source": [
    "## The performance of KNN can be measured using a variety of metrics, depending on the type of task being performed.\n",
    "## Accuracy.\n",
    "## Precision.\n",
    "## F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cafa1c6-1881-4d99-a96a-ff685c175770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "371d1eb4-2dfb-42b2-84e7-9ef4b8cbd897",
   "metadata": {},
   "source": [
    "## Q5. What is the curse of dimensionality in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbfa26e-64f3-4dab-b3a1-8901cc764776",
   "metadata": {},
   "source": [
    "## The dimensionality curse phenomenon states that in high dimensional spaces distances between nearest and farthest points from query points become almost equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a420af7-83d9-4051-b136-5a38b8fde48e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6791a788-1e90-4838-b3da-ea750f153a70",
   "metadata": {},
   "source": [
    "## Q6. How do you handle missing values in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057f7c15-4c50-43fd-ae68-f5c85a8a598e",
   "metadata": {},
   "source": [
    "## There are two main ways to handle missing values in KNN:\n",
    "## Remove the data points with missing values.\n",
    "## Impute the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37042c5b-e36a-4d5f-8760-e6493a12eb53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4a85bdf-573a-46e7-8d32-c249859bc883",
   "metadata": {},
   "source": [
    "## Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for which type of problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ed8c17-f5a8-496f-b632-cfa6a6e7a2c1",
   "metadata": {},
   "source": [
    "## The performance of the KNN classifier and regressor will vary depending on the specific dataset and problem being solved. However, in general, the KNN classifier is better suited for classification tasks, while the KNN regressor is better suited for regression tasks.\n",
    "## The KNN classifier is better suited for classification tasks because it is able to capture the complex relationships between the features in the data. The KNN regressor is better suited for regression tasks because it is able to smooth out the noise in the data and produce more accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4e373-7a41-4d2d-8428-f5d63ca96329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec49e46f-78bd-4f1a-b235-46699c78a9af",
   "metadata": {},
   "source": [
    "## Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks, and how can these be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792c3411-55d3-400f-ab11-f44fda36e223",
   "metadata": {},
   "source": [
    "## The KNN algorithm has a number of strengths and weaknesses for both classification and regression tasks.\n",
    "## Strengths of KNN: Simple to understand and implement.  Non-parametric.  Versatile. Robust to outliers.\n",
    "\n",
    "## Weaknesses of KNN: Computationally expensive. Curse of dimensionality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ba778-04c9-47d2-971a-b093a0ed94c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c1f52d0-893a-4a72-a000-6be66259db36",
   "metadata": {},
   "source": [
    "## Q10. What is the role of feature scaling in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e62716c-3ded-49d1-9e23-412fda5eeeb1",
   "metadata": {},
   "source": [
    "## Feature scaling plays an important role in KNN, as it helps to improve the performance of the algorithm by making the distance metrics more comparable.\n",
    "\n",
    "## Distance metrics are used in KNN to measure the similarity between data points. When the features are on different scales, the distance metrics can be biased towards the features with larger scales. This can lead to inaccurate results, as the algorithm may give more weight to features with larger scales when predicting the class or value of a new data point.\n",
    "\n",
    "## Feature scaling helps to address this problem by transforming the features to a comparable scale. This can be done using a variety of techniques, such as min-max scaling and standard scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d6308f-2461-4461-b850-7d660c271381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
